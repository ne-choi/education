---
title: "Ⅹ. k-인접기법과 판별분석"
author: "ne_choi"
date: '2020 12 08 '
output:
  html_document:
   toc: true
   toc_float:
     collapsed: false
     smooth_scroll: true
   theme: united
   highlight: textmate
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

- POSTECH에서 제공하는 [MOOC](https://pabi.smartlearn.io/) 중, 머신러닝기법과 R프로그래밍 Ⅰ 과정입니다.  

# Ⅹ. k-인접기법과 판별분석
## 1. k-인접기법
- k-nearest neighbor

### 분류(Classification)
- 분류(Classification): 지도학습(Supervised Learning)
  - 타겟범주를 알고 있는 데이터로 분류 규칙을 생성하고 새로운 데이터를 특정 범주에 분류하는 기법

- 군집화(Clustering): 비지도학습(Unsupervised Learning)
  - 독립변수들의 속성을 기반으로 객체들을 그룹화하는 방법

### k-인접기법
- k-인접방법 (kNN): k개의 가장 가까운 이웃을 사용해서 분류하는 방법
  - 거리만 고려하거나, 거리에 따라 가중치를 부여하는 2가지 방법
  - 사용되는 변수에 결측치가 있는 경우, 미리 처리하고 수행해야 함
  - k개의 인접한 관측치의 다수 범주로 할당하는 방법

- 최적 k는?
  - k가 너무 크면 데이터 구조를 파악하기 어렵고, 너무 작으면 과적합(overfitting) 위험이 있음
  - 교차검증(Cross-validation)으로 정확도가 높은 k를 선정

- 장점
  - 단순하며 효율적
  - 데이터 분산을 추정할 필요가 없음
  - 빠른 훈련 단계

- 단점
  - 모델을 생성하지 않음
  - 느린 분류 단계
  - 많은 메모리 필요
  - 결측치는 추가 작업 필요

- kNN 수행을 위한 패키지 설치
```{r}
# packages
# install.packages("class") #no weighted value knn
# install.packages("gmodels") #검증에 사용되는 cross table을 위한 패키지
# install.packages("scales") #for graph
library(class)
library(gmodels)
library(scales)
```


- train/test 데이터 분할(cross-validation)
```{r}
# read csv file
iris <- read.csv("data/week10_1/iris.csv")
# head(iris)
# str(iris)
attach(iris)
```

```{r}
# training/ test data : n=150
set.seed(1000, sample.kind="Rounding")
N=nrow(iris)
tr.idx=sample(1:N, size=N*2/3, replace=FALSE)

# attributes in training and test
iris.train<-iris[tr.idx,-5]
iris.test<-iris[-tr.idx,-5]
# target value in training and test
trainLabels<-iris[tr.idx,5]
testLabels<-iris[-tr.idx,5]

train<-iris[tr.idx,]
test<-iris[-tr.idx,]
```

- kNN 수행과 결과
  - kNN 함수: knn(train=학습데이터, test=검증데이터, cl=타겟변수, k= )
```{r}
# knn (5-nearest neighbor)
md1 <- knn(train=iris.train,test=iris.test,cl=trainLabels,k=5)
md1
```

- kNN(k=5)의 결과: 정확도
```{r}
# accuracy of 5-nearest neighbor classification
CrossTable(x=testLabels,y=md1, prop.chisq=FALSE)
# x: 타겟변수의 실제값, y: 타겟변수의 예측값
```
- 결과 해석
  - 정확도: 47/50 → 94%
  - versicolor를 virginica로 오분류(2개)
  - virginica를 versicolor로 오분류(1개)
  - 오분류율: 3/50 → 6%  


## 2. k-인접기법: 가중치
### kNN에서 최적 k 탐색
- 최적 k의 탐색: 1 to nrow(tran_data)/2 (여기서는 1 to 50)

```{r}
# optimal k selection (1 to n/2)
accuracy_k <- NULL
# try k=1 to nrow(train)/2, may use nrow(train)/3(or 4,5) depending the size of n in train data
nnum<-nrow(iris.train)/2
for(kk in c(1:nnum))
{
  set.seed(1234, sample.kind="Rounding")
  knn_k<-knn(train=iris.train,test=iris.test,cl=trainLabels,k=kk)
  accuracy_k<-c(accuracy_k,sum(knn_k==testLabels)/length(testLabels))
}

# plot for k=(1 to n/2) and accuracy
test_k<-data.frame(k=c(1:nnum), accuracy=accuracy_k[c(1:nnum)])
plot(formula=accuracy~k, data=test_k,type="o",ylim=c(0.5,1), pch=20, col=3, main="validation-optimal k")
with(test_k,text(accuracy~k,labels = k,pos=1,cex=0.7))
```

```{r}
# minimum k for the highest accuracy
min(test_k[test_k$accuracy %in% max(accuracy_k),"k"])
```
- 결과 해석
  - k=7에서 정확도(.98)가 가장 높음


- 최종 kNN 모형 (k=7)
```{r}
#k=7 knn
md1<-knn(train=iris.train,test=iris.test,cl=trainLabels,k=7)
CrossTable(x=testLabels,y=md1, prop.chisq=FALSE)
```
- 결과 해석
  - 정확도: 49/50 → 98%
  - versicolor를 virginica로 오분류 (1개)
  - 오분류율: 1/50 → 2%


- kNN(k=7)의 결과: 그래픽
```{r}
# graphic display
plot(formula=Petal.Length ~ Petal.Width,
     data=iris.train,col=alpha(c("purple","blue","green"),0.7)[trainLabels],
     main="knn(k=7)")
points(formula = Petal.Length~Petal.Width,
       data=iris.test,
       pch = 17,
       cex= 1.2,
       col=alpha(c("purple","blue","green"),0.7)[md1]
)
legend("bottomright",
       c(paste("train",levels(trainLabels)),paste("test",levels(testLabels))),
       pch=c(rep(1,3),rep(17,3)),
       col=c(rep(alpha(c("purple","blue","green"),0.7),2)),
       cex=0.9
)
```
- 결과 해석
  - Petal.width와 Petal.length에 산점도를 그리면 setosa는 잘 분류됨
  - virginica와 versicolor는 분류가 잘 되지 않음

### Weighted kNN
- 거리에 따라 가중치를 부여하는 두 가지 알고리즘이 존재
```{r}
# Weighted KNN packages
# install.packages("kknn") # weighted value knn
library(kknn)
```

- k=5, distance=1
```{r}
# weighted knn
md2 <- kknn(Species~., train=train, test=iris.test, k=5, distance=1, kernel="triangular")
md2

# to see results for weighted knn
md2_fit<-fitted(md2)
md2_fit
```

- cross table로 오분류율 보기
```{r}
# accuracy of weighted knn
CrossTable(x=testLabels,y=md2_fit,prop.chisq=FALSE,prop.c=FALSE)
```

- k=7, distance=2로 옵션 변경 결과
```{r}
# weighted knn (k=7, distance=2)
md3<-kknn(Species~., train=train,test=iris.test,k=7,distance=2,kernel="triangular")
md3
# to see results for weighted knn
md3_fit<-fitted(md3)
md3_fit
# accuracy of weighted knn
CrossTable(x=testLabels,y=md3_fit,prop.chisq=FALSE,prop.c=FALSE)
```

## 3. 판별분석 Ⅰ
### 판별분석
- 데이터 마이닝 분류 기법 중 하나

