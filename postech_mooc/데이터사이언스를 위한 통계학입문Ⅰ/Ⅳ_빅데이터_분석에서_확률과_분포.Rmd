---
title: "Ⅳ. 빅데이터 분석에서 확률과 분포"
author: "ne_choi"
date: '2020 11 24 '
output:
  html_document:
   toc: true
   toc_float:
     collapsed: false
     smooth_scroll: true
   theme: united
   highlight: textmate
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

* POSTECH에서 제공하는 [MOOC](https://pabi.smartlearn.io/) 중, 데이터사이언스를 위한 통계학입문 Ⅰ 과정입니다.

# Ⅳ. 빅데이터 분석에서 확률과 분포
## 1. 확률의 기초개념

### 통계에 확률 개념이 필요한 이유
- **통계(Statistics)**
  - 데이터를 수집, 처리, 분석, 활용하는 지식
  - 실제 얻어진 데이터를 바탕으로 정보 도출
  
- **확률(Probabilities)**
  - 특정 사건이 일어날 가능성을 0과 1 사이 값으로 나타낸 것
  - 관측 전에 가능성을 논하는 것

- 현실 세계는 매우 랜덤하여 미리 결과를 알 수 없음
- 단기적으로 어떤 사건이 일어날 비율은 매우 랜덤함
- 단, 장기적으로 어떤 사건이 일어날 가능성은 **확률적으로 예측 가능**

### 확률, 사건, 표본공간
- 확률: 특정 사건이 일어날 가능성을 0과 1 사이 값으로 나타낸 것
- 사건: 표본공간에서 관심 대상인 부분집합
- 표본공간: 확률실험의 모든 가능한 결과의 집합
- P(A) = $\frac{사건 A가 일어나는 경우의 수}{모든 가능한 결과의 수}$
<br>

- 합집합사건: 사건 A 또는 사건 B가 일어날 때
- 교집합사건: 사건 A와 사건 B가 동시에 일어날 때
- 여집합사건: 표본공간 S에서 사건 A가 일어나지 않을 때
- 배반사건: 교집합사건이 공사건일 때, 사건 A와 B가 서로 배반(mutually exclusive)

### 확률변수와 기대값
- 확률변수: 확률 실험에서 나타난 결과에 실수를 할당한 점수

  | 표본공간 | 확률변수 |
  |---|---|
  | HH | 0 |
  | HT | 1 |
  | TH | 1 |
  | TT | 2 |

- 기대값: 확률변수의 중심척도
  - 랜덤한 상황에서 수치로 나타난 결과가 A~1~, A~2~, ..., A~k~이고 각 결과 확률이 P~1~, P~2~, ..., P~k~면 기대값은 각 결과에 확률을 곱하여 전부 합한 것
  - 기대값 = A~1~P~1~ + A~2~P~2~ + ... + A~k~P~k~

### 요약
- 확률: 특정 사건이 일어날 가능성을 0과 1 사이 값으로 나타낸 것
- 사건 하나하나를 미리 아는 것은 불가능하지만, 확률적 모형으로 많은 시행 결과 예측이 가능
- 표본공간과 사건을 밴다이어그램으로 나타내 특정 사건에 관한 확률을 구할 수 있음
- 확률변수: 확률 실험으로부터 나타난 결과에 실수를 할당한 함수


## 2. 조건부 확률과 베이즈확률
### 조건부 확률과 통계적 독립
- 예제
  - 두 개의 주사위를 던져 두 눈 합이 10일 확률: 1/12
  - 첫 번째 주사위 눈이 4라는 것을 아는 상황
  - 두 눈의 합이 10일 확률은?
  - → 확률이 1/6으로 바뀜
<br>

- 조건부 확률(conditional probability)
  - 어떤 사건(B)이 발생한다는 조건 하에서 다른 사건(A)이 발생할 확률
  - P(A|B) = $\frac{P(A∩B)}{P(B)}$

- P(A|B) = P(A)일 때, 즉 사건 B가 일어난다는 정보가 사건 A 발생에 전혀 영향을 주지 않을 때, '두 사건이 통계적 독립(independent)'이라고 한다.

### 베이즈 정리
- 베이즈 정리(Bayes' Theorem)
  - P(A~1~|B) = $\frac{P(B∩A~1~)}{P(B)}$
    = $\frac{P(B|A~1~)P(A~1~)}{P(B)}$
    = $\frac{[P(B|A~1~)P(A~1~)]}{P(B|A~1~)P(A~1~) + P(B|A~2~)P(A~2~)}$

- 베이즈 정리도 아래와 같은 조건부 확률 계산식으로 볼 수 있음
  - P(A~1~|B) = $\frac{P(B∩A~1~)}{P(B)}$
    - 사건 B가 발생했을 때, 사건 A~1~이 발생할 확률을 조건부 확률 공식으로 표현
  - $\frac{P(B|A~1~)P(A~1~)}{P(B)}$
    - P(B|A~1~)에 대한 조건부 확률 공식 이용
  - $\frac{[P(B|A~1~)P(A~1~)]}{P(B|A~1~)P(A~1~) + P(B|A~2~)P(A~2~)}$
    - P(B)를 P(B∩A~1~) + P(B∩A~2~)로 계산할 수 있음

- 주어진(사전정보) 가설에 새로운 정보(B)가 주어졌을 때, 사후확률을 계산함
  - $\frac{[P(B|A~1~)P(A~1~)]}{P(B|A~1~)P(A~1~) + P(B|A~2~)P(A~2~)}$
  - P(B|A~1~): 가농도, P(A~1~): 사전확률
  
### 요약
- 조건부 확률: 어떤 사건이 발생한다는 조건 하 다른 사건이 발생할 확률
- 베이즈 정리: 사후확률을 사전확률과 가능도를 이용해 계산할 수 있게 하는 확률 변환식
- 머신러닝기법 중, '나이브베이즈 분류' 기법 계산에서 베이즈정리가 활용됨


## 3. 정규분포(연속형)와 포아송분포(이산형)
### 확률분포란?
- 확률분포에는 이산형(discrete) 분포와 연속형(continuous) 분포가 있음
  - 이산형 분포: 점이 띄엄띄엄 분포되어 있음
  - 연속형 분포: 점이 연속적으로 분포되어 있음

### 이산형 분포
- 확률변수가 이산형(discrete)일 때의 확률분포
  - 기대값 E(X) = Σx*p(x) ← 가중치 평균의 개념
  - 분산 Var(X) = E(X^2^) - E(X)^2^
- 이항분포, 다항분포, 초기하분포, 포아송분포 등

1. **이항분포**
   - 어떤 시행의 결과가 단순히 '성공' 또는 '실패'로 나타날 때(베르누이 시행), 성공이 나오는 횟수에 대한 확률분포
   - 성공화귤이 p인 베르누이시행을 n회 반복할 때 성공 횟수 X
   - E(X) = np
   - Var(X) = np(1-p)

2. **포아송분포**
   - 단위 시간 안에 어떤 사건이 몇 번 발생하는가에 대한 확률분포
   - 확률변수 X가 포아송확률변수이고, 모수(평균발생횟수)가 λ
   - E(X) = λ
   - Var(X) = λ

### 연속형 분포
- 확률변수가 연속형(continuous)일 때의 확률분포
- 연속형 분포에서는 정규분포(Normal distribution)가 가장 중요함
  - 모집단의 분포가 정규분포를 가진다고 가정하면 통계 분석이 쉬워짐
  - 사회적 자연적 현상 통계치의 분포가 정규분포와 비슷한 형태를 띔

1. **표준정규분포**
   - 평균이 0이고 분산이 1인 정규분포
   - 정규분포를 표준정규분포로 만드는 법
     - X~N(μ,σ^2^) → Z = $\frac{X-μ}{σ}$~N(0,1)
   - 표준화를 하는 이유?
     - 표준정규분포에서의 구간 면적을 미리 구해두면 이를 이용해서 모든 정규분포 면적을 구할 수 있음

2. **카이제곱(x^2^)분포**
   - 확률변수 Z가 표준정규분포 N(0,1)을 따를 때, z^2^은 자유도가 1인 카이제곱분포를 따름

3. **F-분포**
   - 두 확률변수 X~1~^2^과 x~2~^2^이 서로 독립이며, 각각의 자유도가 v~1~, v~2~인 카이제곱분포를 따를 때, 확률변수 F는 자유도가 (v~1~, v~2~)인 F-분포를 따름

### 요약
- 이산형 분포: 확률변수가 이산형일 때의 확률분포
- 이항분포: 베르누이시행에서 '성공'이 나오는 횟수에 대한 확률분포
- 포아송 분포: 단위시간 안에 어떤 사건이 몇 번 발생하는가에 대한 확률분포
- 연속형 분포: 확률변수가 연속형일 때의 확률분포
- 정규분포: 정규분포는 평균을 중심으로 대칭을 이루는 종모양의 연속확률분포


## 4. 데이터에서 출발하는 확률과 분포(중심극한)
### 현실의 분포
- 현실의 다양한 분포 → 설명할 수 없는 분포 존재
- 중심극한정리(central limit theorem)

### 중심극한정리
- 이항분포에서 표본 수가 증가함에 따라 표본들의 전체 합이 점점 정규분포에 근접해짐

- 지수분포에서도 표본 수의 증가에 따른 표본평균의 분포가 점점 정규분포와 비슷해짐

- 원래의 분포가 정규분포가 아니더라도, 표본 수가 증가함에 따라 표본평균이 점점 정규분포모형과 비슷해짐

### 중심극한정리 정리
- 모집단이 정규분포가 아닌 경우에도 표본 수가 증가하면 표본평균의 분포가 정규분포에 근접
- 평균이 μ이고 분산이 σ^2^인 모집단으로부터 크기 n인 확률표본을 추출할 때, n이 크면 표뵨평균 X는 N(μ, σ^2^/n)에 근접
- 보통 n이 30 이상이면 모집단의 분포에 관계 없이 X는 정규분포에 근사

### 중심극한정리가 유용한 이유
- 대부분의 통계적 검정과 추정은 모집단이 정규분포를 따른다는 가정 하에 이루어짐
  - → 모집단의 분포를 몰라도 중심극한정리를 이용하면 표본평균의 통계적 검정과 추정이 가능해짐

### 요약
- 중심극한정리란 모집단의 분포에 관계 없이 표본의 수가 증가하면 표본평균의 분포가 정규분포에 근접한다는 이론
- 평균이 μ이고 분산이 σ^2^인 모집단으로부터 크기 n(≥ 30)인 확률표본을 추출할 때 표본평균 X는 N(μ, σ^2^/n)에 근접
- 모집단의 분포를 몰라도 중심극한정리를 이용하면 표본평균의 통계적 검정과 추정이 가능해짐
